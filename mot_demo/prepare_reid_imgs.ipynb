{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaipham/anaconda3/envs/mmrotate1x/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`\n",
      "1.0.0rc1\n"
     ]
    }
   ],
   "source": [
    "__author__ = \"Thaiph99\"\n",
    "\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "from mmengine.runner import load_checkpoint\n",
    "from mmdet.registry import VISUALIZERS\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "import mmrotate\n",
    "import mot.mot_utils as utils\n",
    "from mot.jde_tracker import JDETracker\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(mmrotate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../rotated_rtmdet_l_3x_v4/epoch_96.pth\n"
     ]
    }
   ],
   "source": [
    "# init detection model\n",
    "# config = \"configs/rotated_rtmdet/rotated_rtmdet_m-3x-dota_ms_custom_v1.py\"\n",
    "config = \"../rotated_rtmdet_l_3x_v4/rotated_rtmdet_l-3x-dota_ms_custom_v4.py\"\n",
    "checkpoint = \"../rotated_rtmdet_l_3x_v4/epoch_96.pth\"\n",
    "device = 'cuda:0'\n",
    "model = init_detector(config, checkpoint, device)\n",
    "\n",
    "labels_name = (\"paper\", \"metal\", \"plastic\", \"nilon\", \"glass\", \"fabric\")\n",
    "tracker = JDETracker(use_byte=True, num_classes=len(labels_name))\n",
    "\n",
    "# cv2 config params\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.7\n",
    "font_thickness = 2\n",
    "font_color = (255, 255, 255)\n",
    "text_offset = np.array([0, -10]).reshape((1, 1, -1)).astype(np.int32)\n",
    "pi = 22/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = \"/home/thaipham/Videos/output2.avi\"\n",
    "# video_path = \"/home/thaipham/Videos/2023-07-24-094036.webm\"\n",
    "# video_path = \"/home/thaipham/Videos/2023-07-24-094422.webm\"\n",
    "video_path = \"/home/thaipham/Videos/2023-07-24-094907.webm\"\n",
    "# video_path = 0\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "data_dir = '/home/thaipham/horus/data/reid_data'\n",
    "imgs_dir = os.path.join(data_dir, 'imgs')\n",
    "meta_dir = os.path.join(data_dir, 'meta')\n",
    "\n",
    "frame_id = 0\n",
    "id_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count id for vid /home/thaipham/Videos/2023-07-24-094907.webm is 724\n"
     ]
    }
   ],
   "source": [
    "while (cap.isOpened()):\n",
    "    # time.sleep(0.1)\n",
    "    ret, frame = cap.read()\n",
    "    fake_frame = np.copy(frame)\n",
    "\n",
    "    frame_id += 1\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    outs = inference_detector(model, frame)\n",
    "\n",
    "    bboxes = outs.pred_instances.bboxes.cpu().numpy()\n",
    "    pred_scores = outs.pred_instances.scores.cpu().numpy()\n",
    "    labels = outs.pred_instances.labels.cpu().numpy()\n",
    "\n",
    "    confidence_threshold = 0.55\n",
    "    filtered_indices = np.where(pred_scores > confidence_threshold)[0]\n",
    "\n",
    "    bboxes = bboxes[filtered_indices]\n",
    "    pred_scores = pred_scores[filtered_indices]\n",
    "    labels = labels[filtered_indices]\n",
    "\n",
    "    if bboxes.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # for bbox in bboxes:\n",
    "    #     xc, yc, width, height, radian = bbox\n",
    "    #     degrees = radian * (180/pi)\n",
    "    #     points = cv2.boxPoints(([xc, yc], (width, height), degrees))\n",
    "    #     pts = np.array(points).reshape((1, -1, 1, 2)).astype(np.int32)\n",
    "    #     cv2.polylines(frame, pts, True, (0, 255, 0), 2)\n",
    "\n",
    "    over_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        xc, yc, width, height, radian = bbox\n",
    "        degrees = radian * (180/pi)\n",
    "        points = cv2.boxPoints(([xc, yc], (width, height), degrees))\n",
    "        bbox_tlbr = np.array([np.min(points[:, 0]), np.min(points[:, 1]),\n",
    "                              np.max(points[:, 0]), np.max(points[:, 1])])\n",
    "        over_bboxes.append(bbox_tlbr)\n",
    "        bbox_tlbr = bbox_tlbr.astype(int)\n",
    "        # cv2.rectangle(frame, bbox_tlbr[0:2], bbox_tlbr[2:4], (0, 0, 255), 2)\n",
    "\n",
    "    over_bboxes = np.array(over_bboxes)\n",
    "\n",
    "    # convert xywh to tlbr\n",
    "    # pred_bboxes = np.asarray(bboxes[:, 0:4]).copy()\n",
    "    # pred_bboxes = np.concatenate((bboxes[:, 0:2] - bboxes[:, 2:4]/2,\n",
    "    #                               bboxes[:, 0:2] + bboxes[:, 2:4]/2),\n",
    "    #                              axis=1)\n",
    "\n",
    "    # reshape numpy array from (n,0) to (n,1)\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    pred_scores = pred_scores.reshape(-1, 1)\n",
    "    # pred_dets_old = np.concatenate((labels, pred_scores, pred_bboxes), axis=1)\n",
    "\n",
    "    pred_dets_old = np.concatenate((labels, pred_scores, over_bboxes), axis=1)\n",
    "\n",
    "    pred_dets_dict = defaultdict(list)\n",
    "    for cls_id in range(len(labels_name)):\n",
    "        cls_idx = (pred_dets_old[:, 0:1] == cls_id).squeeze(-1)\n",
    "        pred_dets_dict[cls_id] = pred_dets_old[cls_idx]\n",
    "\n",
    "    online_targets_dict = tracker.update(pred_dets_old)\n",
    "    online_tlwhs = defaultdict(list)\n",
    "    online_scores = defaultdict(list)\n",
    "    online_ids = defaultdict(list)\n",
    "    for cls_id in range(tracker.num_classes):\n",
    "        online_targets = online_targets_dict[cls_id]\n",
    "\n",
    "        for idx_det, t in enumerate(online_targets):\n",
    "            tlwh = t.tlwh\n",
    "            tid = t.track_id\n",
    "            tscore = t.score\n",
    "\n",
    "            # visualize detector and tracker\n",
    "            det = t.det\n",
    "\n",
    "            # convert tlwh to tlbr\n",
    "            points = np.asarray(tlwh).copy()\n",
    "            if len(det) != 0:\n",
    "                points = np.asarray(det).copy()\n",
    "            else:\n",
    "                points = np.asarray(tlwh).copy()\n",
    "\n",
    "            points[2:4] = points[0:2] + points[2:4]\n",
    "            intbox = points.astype(int)\n",
    "            cv2.rectangle(frame, intbox[0:2], intbox[2:4], (0, 0, 255), 2)\n",
    "\n",
    "            # visualize object id\n",
    "            obj_id = tid\n",
    "            id_set.add(obj_id)\n",
    "            text = f\"#{obj_id}\"\n",
    "            frame = cv2.putText(frame, text, (intbox[0], intbox[1] - 10), font_face,\n",
    "                                font_scale, (0, 200, 255), font_thickness, cv2.LINE_4,)\n",
    "\n",
    "            # save online\n",
    "            if tlwh[2] * tlwh[3] <= tracker.min_box_area:\n",
    "                continue\n",
    "            if tracker.vertical_ratio > 0 and tlwh[2] / tlwh[\n",
    "                    3] > tracker.vertical_ratio:\n",
    "                continue\n",
    "\n",
    "            # write reid data\n",
    "\n",
    "            # obj_str = 'obj_{}'.format(obj_id)\n",
    "            # obj_fol = os.path.join(imgs_dir, obj_str)\n",
    "            # if not os.path.exists(obj_fol):\n",
    "            #     os.mkdir(obj_fol)\n",
    "\n",
    "            t, l, b, r = intbox[0:4]\n",
    "            t = max(0, t)\n",
    "            t = min(t, frame.shape[1])\n",
    "\n",
    "            b = max(0, b)\n",
    "            b = min(b, frame.shape[1])\n",
    "\n",
    "            l = max(0, l)\n",
    "            l = min(l, frame.shape[0])\n",
    "\n",
    "            r = max(0, r)\n",
    "            r = min(r, frame.shape[0])\n",
    "\n",
    "            frame_splited = fake_frame[l:r, t:b]\n",
    "\n",
    "            img_name = 'img_{}_{}.jpg'.format(obj_id, frame_id)\n",
    "            # cv2.imwrite(os.path.join(obj_fol, img_name), frame_splited)\n",
    "\n",
    "            # cv2.imshow('Frame', frame_splited)\n",
    "\n",
    "            online_tlwhs[cls_id].append(tlwh)\n",
    "            online_ids[cls_id].append(tid)\n",
    "            online_scores[cls_id].append(tscore)\n",
    "\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Press Q on keyboard to exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('count id for vid {} is {}'.format(video_path, len(id_set)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrotate1x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
